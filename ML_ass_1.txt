
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import  RandomForestRegressor
from sklearn.metrics import  mean_squared_error

df = pd.read_csv('uber.csv')

df.head()

df.info()

df.isnull().sum()

df.dropna(inplace=True)
df.isna().sum()

df.drop_duplicates(inplace=True)

df.info()
   
df.columns

df.describe() 

df.columns

df.pickup_datetime=pd.to_datetime(df.pickup_datetime)
df['year'] = df.pickup_datetime.dt.year
df['month'] = df.pickup_datetime.dt.month
df['weekday'] = df.pickup_datetime.dt.weekday
df['hour'] = df.pickup_datetime.dt.hour

df.info()

df.drop_duplicates(inplace=True)
df.drop(['Unnamed: 0','key'], axis=1, inplace=True)
df.drop(['pickup_datetime','month', 'hour',], axis=1, inplace=True)

##OUTERLIERS DETECTION 
sns.distplot(df['fare_amount'])
#%%
sns.distplot(df['pickup_latitude'])
#%%
sns.distplot(df['pickup_longitude'])
#%%
sns.distplot(df['dropoff_longitude'])
#%%
sns.distplot(df['dropoff_latitude'])
#%%

nf = []; cf = []; nnf = 0; ncf = 0; 
features1 = nf  # outerliers fnding on numerical features
df1=df.copy()
for i in features1:  
    Q1 = df[i].quantile(0.25)
    Q3 = df[i].quantile(0.75)
    IQR = Q3 - Q1
    df = df[df[i] <= (Q3+(1.5*IQR))]
    df = df[df[i] >= (Q1-(1.5*IQR))]
    df = df.reset_index(drop=True)
df.head()
print('\nBefore removal of outliers, The dataset had {} samples.'.format(df1.shape[0]))
print('After removal of outliers, The dataset now has {} samples.'.format(df.shape[0]))

corrMatrix = df.corr()
sns.heatmap(corrMatrix, annot=True)
plt.show()

X = df.drop(['fare_amount'],axis=1)
Y = df['fare_amount']
Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)

regr = LinearRegression()
regr.fit(Train_X,Train_Y)
print("Linear Regression score R^2 Score ")
regr.score(Test_X, Test_Y)
y_pred_lr = regr.predict(Test_X)
lr_mse = np.sqrt(mean_squared_error(y_pred_lr, Test_Y))
print("RMSE value for Linear regression is:", lr_mse)

rfr = RandomForestRegressor(n_estimators = 20, random_state = 101)
rfr.fit(Train_X,Train_Y)
print("RandomForestRegressor Regression score R^2 Score ")
rfr.score(Test_X, Test_Y)
y_pred_rfr = rfr.predict(Test_X)
rfr_mse = np.sqrt(mean_squared_error(y_pred_rfr, Test_Y))
print("RMSE Value for Random Forest Regression is:", rfr_mse)